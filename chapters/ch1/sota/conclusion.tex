\subsection{Target object misidentification problem}
\label{sec:sota_conclusion}
Section \ref{sec:lfd} provides a detailed overview of classic methodologies for solving the LfD problem. However, all the discussed methods are evaluated in single-task scenarios, meaning the learned policies can only replicate the specific task they are trained on, with limited generalization to new configurations. In collaborative environments, where a robot may need to perform various tasks as requested by a human operator, these systems may fail due to their inability to generalize across different tasks.

To address this limitation, the Multi-Task Imitation Learning problem has been introduced. As discussed in Section \ref{sec:motivation}, the goal is to train a single conditioned control policy that, given the robot current state and the task at hand, generates the appropriate action. These methods are described in detail in Chapter \ref{ch:occp}, where both language-based and video-based conditioning modalities are reviewed.

This thesis specifically focuses on video-conditioned methods. Experimental results in Section \ref{sec:ocpl_experimental} demonstrate that state-of-the-art methods in Video-Conditioned Multi-Task Imitation Learning, such as TOSIL \cite{dasari2021transformers_one_shot} and MOSAIC \cite{mandi2022towards_more_generalizable_one_shot}, face the problem of \textbf{target misidentification} in scenarios with multiple similar objects, where the semantic role of objects (e.g., distractor or object of interest) changes depending on the task.

As a result, while these methods can generate reasonable trajectories and complete tasks, they often manipulate the wrong object. Specifically, it was observed that the backbone failed to produce an embedding that accurately encodes the target object position at the start of the task. Interestingly, by performing ground-truth actions for just two steps at the beginning, the model was able to correctly complete the task. This highlights a gap in learning features related to the cognitive aspect of the task, particularly the position of the object to be manipulated.

To overcome this issue, and building on the observations in Section \ref{sec:motivation} regarding the cognitive and control tasks in multi-task manipulation, this thesis proposes a modular approach. Instead of using an end-to-end architecture that directly maps high-dimensional inputs to the action space, the problem is divided into two sub-problems: the cognitive and control tasks, each addressed by specialized modules. The cognitive module, described in Chapter \ref{ch:cod}, introduces object priors related to the position of the object to be manipulated. Specifically, a Conditioned Object Detection (COD) problem is formulated and solved using a Conditioned Convolutional Neural Network, which predicts category-agnostic bounding boxes for the objects of interest based on the specific prompted variation.

The proposed COD module is then integrated into a state-of-the-art framework to validate the hypothesis that adding inferred object priors can resolve the target misidentification issue. This results in a novel modular architecture, detailed in Chapter \ref{ch:occp}, that can perform both \textit{multi-variation} and \textit{multi-task} manipulation robustly. 

Additionally, it generates human-readable information, enhancing the interpretability of the learned policies by providing insights into the robot intended movements.

