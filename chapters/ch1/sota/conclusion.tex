\subsection{Target object misidentification problem}
\label{sec:sota_conclusion}
Section \ref{sec:lfd} provides a detailed overview of classic methodologies for solving the LfD problem. However, all the discussed methods are evaluated in single-task scenarios, meaning that the learned policies can only replicate the specific task they are trained on, with limited generalization to new configurations. In collaborative environments where a robot may need to perform various tasks as requested by a human operator, these systems may fail due to their inability to generalize across different tasks.

To address this limitation, the Multi-Task Imitation Learning problem has been introduced in literature. As mentioned in Section \ref{sec:motivation}, the goal of these methods is to train a single conditioned control policy that, given the current state of the robot and the task to be performed, can generate the correct action. These methods will be described in detail Chapter \ref{ch:occp}, where both the conditioning modalities language-based and video-based will be reviewed.

However, this thesis specifically focuses on video-conditioned methods. Experimental results in Section \ref{sec:ocpl_experimental} demonstrate that state-of-the-art methods in Video-Conditioned Multi-Task Imitation Learning, such as TOSIL \cite{dasari2021transformers_one_shot} and MOSAIC \cite{mandi2022towards_more_generalizable_one_shot}, suffer from the problem of \textbf{target misidentification} in scenarios with multiple similar objects, where the semantic role of the objects (e.g., distractor or object of interest) changes based on the prompted task. This means that, while these methods can generate reasonable trajectories and complete tasks, they often manipulate the wrong object. Specifically, it was observed that the backbone failed to produce an embedding that encodes the position of the target object at the beginning of the task. In fact, by performing ground-truth actions for just two steps at the very start, the model was able to complete the task correctly. This highlights a lack in learning features related to the cognitive aspect of the task, specifically, the position of the object to be manipulated.

To overcome this issue, and building upon the observations made in Section \ref{sec:motivation} regarding the cognitive and control tasks involved in multi-task manipulation, this thesis proposes a modular approach. Rather than using an end-to-end architecture that maps high-dimensional inputs directly to the action space, the problem is divided into two sub-problems: the cognitive and control problems, each addressed by specialized modules. The cognitive module, described in Chapter \ref{ch:cod}, introduces object priors related to the position of the object to be manipulated. Specifically, a Conditioned Object Detection problem is formulated and solved using a Conditioned Convolutional Neural Network, which predicts a category-agnostic bounding boxes for the objects of interest for the specific prompted variation.

The proposed COD module is then integrated into a state-of-the-art framework to validate the hypothesis that adding inferred object priors can resolve the target misidentification issue. This leads to a novel modular architecture, detailed in Chapter \ref{ch:occp}, capable of performing both \textit{multi-variation} and \textit{multi-task} manipulation robustly. Additionally, it generates human-readable information, enhancing the interpretability of the learned policies by providing insights into the robot's intended movements.
