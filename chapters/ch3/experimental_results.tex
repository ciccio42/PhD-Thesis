\section{Experimental results}
\label{sec:ocpl_experimental}

In this section, the performed experiments are going to be described. Specifically, in  
Section~\ref{sec:ocpl_dataset} the dataset used for training procedure will be described. Section~\ref{sec:ocpl_results} will report the obtained results.
\input{figures/ch3/dataset_distribution.tex}
\subsection{Dataset}
\label{sec:ocpl_dataset}
The dataset used for training the control architectures is described in this section. It consists of the same tasks outlined in Section \ref{sec:cod_dataset}, following the same collection procedure. For each task variation, 100 trajectories were collected for both the agent and the demonstrator. Each trajectory presents a novel object configuration, according to the rules defined in Section \ref{sec:cod_dataset}.

In this section, the dataset is analyzed in terms of the distribution of the action space, in order to highlight the challenges from a control perspective.

Figure \ref{fig:dataset_distribution} illustrates the distribution of the trajectories followed by the robot. Each plot represents a density map illustrating the frequency with which the robot's end-effector passed through specific points across all variations and trajectories. Notably, the use of a simulated environment enables complete coverage of the workspace. This particular aspect of the workspace coverage will be further discussed in Chapter \ref{ch:real_world_application} where the real-world system will be discussed.


% \smalltodo{Add figure here.}

Notably, each task exhibits a \textbf{multi-modal behavior}. This is evident across different variations, as the final placing position changes with each variation. Additionally, during the reaching phase, the robot traverses almost all possible locations within the working area.

It is important to note that, for a given task, the trajectories exhibit significant variation in length. Specifically, for the Pick-Place task, the average trajectory length is \textbf{$71.21 \pm 7.69$} frames. In the Nut-Assembly task, the average length is \textbf{$62.24 \pm 7.47$} frames, while for the Stack-Block task, the average is \textbf{$63.07 \pm 1.51$} frames. Finally, in the Press-Button task, the average trajectory length is\textbf{ $40.45 \pm 8.17$} frames. 

This variability poses a challenge, as the likelihood of errors increases with task progression, and compounding errors become more pronounced over time. Additionally, this multi-modal behavior complicates the learning process. The dataset lacks any prior distribution (i.e., the robot does not consistently approach the target object from the same direction), making it challenging for the architecture to identify and leverage consistent patterns during training.

\subsection{Results}
\label{sec:ocpl_results}
This section presents the obtained results, divided into two main blocks. The first block (Section~\ref{sec:ocpl_results_scm}) discusses the results of the method described in Section\ref{sec:ocpl_architecture_scm}. The second block (Section~\ref{sec:ocpl_results_dcm}) covers the results of the method described in \ref{sec:ocpl_architecture_dcm}. For each method, results are reported for two different scenarios: first, where the method is trained in a single-task multi-variation scenario; and second, where the method is trained in a multi-task multi-variation scenario.

The tests are conducted following the procedure outlined in Section \ref{sec:cod_results}. For each variation, 10 independent runs are performed, each with a novel initial objects configuration. This approach assesses the system robustness with respect to different initial state configurations. Additionally, each set of 10 rollouts is repeated three times to evaluate the overall robustness and consistency of the model.

Various evaluation metrics are considered, either generally defined for each task or task-specific. The general metrics include:

\begin{itemize}
    \item \textit{Reaching}: The ratio of successful attempts where the robot reaches the target object across all rollouts.
    \item \textit{Picking}: The ratio of successful attempts where the robot picks the correct object across all rollouts.
    \item \textit{Success}: The ratio of successful task completions across all rollouts.
    \item \textit{Reaching Wrong}: The ratio of instances where the robot reaches an object other than the target across all rollouts.
    \item \textit{Picking Wrong}: The ratio of instances where the robot picks the wrong object across all rollouts.
    \item \textit{Success with Wrong Object}: The ratio of task completions where the robot manipulates the wrong object.
\end{itemize}

Task-specific metrics, particularly for tasks like Pick-Place and Nut-Assembly, include:

\begin{itemize}
    \item \textit{Place Wrong with Wrong Object}: The number of times the robot completes the task by placing the wrong object in the wrong position.
    \item \textit{Place Wrong with Correct Object}: The number of times the robot completes the task by placing the correct object in the wrong position.
\end{itemize}

These metrics provide a comprehensive evaluation of the robot performance, capturing all major error cases and giving a full picture of its behavior.

\subsubsection{Single control module}
In this section the results obtained with the architecture composed of a Single Control Module will be described. As in Chapter \ref{ch:cod}, there are two testing scnearios, the first one trained with a single-task  multi-variation scenario, while the second one with a multi-task multi-variation setting, with an increasing level of complexity.
\label{sec:ocpl_results_scm}
\paragraph*{Single-task multi-variation scenario}\mbox{}\\

The discussion of the results begins with the single-task multi-variation scenario, focusing on the baseline methods TOSIL \cite{dasari2021transformers_one_shot} and MOSAIC \cite{mandi2022towards_more_generalizable_one_shot}. Specifically, Table \ref{table:occp_single_task_baseline_res} presents the performance of these baseline methods. 
\input{tables/ch3/baseline_single_task.tex}

As observed, both baseline methods suffer from the issue of \textbf{target-object misidentification}. This is evident from the \textit{Success with Wrong Object} column, where the success rate involving wrong objects is significant. Figure \ref{fig:baseline_pick_place_error} provides an example of a pick-and-place rollout in which the task is technically completed, but the wrong object is manipulated.
\input{figures/ch3/pick_place_error.tex}
% \smalltodo{Add Figure}

To investigate the cause of these errors, test rollouts were performed using the first 2 and 10 actions generated by a hand-written policy, which has access to ground-state information. As noted, the success rate improves substantially by applying just 2 ground-truth actions. This supports the hypothesis outlined in Section \ref{sec:ocpl_problem}, suggesting that the end-to-end architecture trained with an action-centric loss produces a suboptimal embedding $z$ for the cognitive task. The embedding fails to sufficiently inform the control policy about the correct position of the target object.

Based on this consideration, the thesis proposal to inform the control module with both a low-level positional information (e.g., the bouding-box of the target object) and a control embedding generated by the MOSAIC-backbone has been tested. During this test, two models variations have been considered, the first named \textit{MOSAIC-GT-BB} is basically the MOSAIC model, with the Control Module that receives in input the control-embedding $z^{control}$ and the ground-truth bouding-box. The second, named \textit{MOSAIC-CTOD} is the architecture described in Section \ref{sec:ocpl_architecture_scm}.

\input{tables/ch3/ctod_single_task.tex}
The results are summarized in Table \ref{table:ctod_single_task_performance}. Several key observations can be made from these findings. For tasks involving multiple similar objects that change positions across different demonstrations (such as Pick-Place, Nut-Assembly, and Stack-Block), the use of positional information significantly enhances the system robustness. This enables the robot to consistently reach the target object and improves the overall success rate.

In contrast, for the Press-Button task, although the MOSAIC-CTOD method achieves a high success rate (95.56\% on average), it does not overcome the baseline method, which consistently solves the task with a 100\% success rate. This is because, once the button is reached, the positional information does not provide any additional guidance on how to complete the task. As a result, the robot tends to get stuck near the button, failing to execute the pushing action (Figure \ref{fig:button_ctod_error}).
\input{figures/ch3/button_ctod_error.tex}
% \smalltodo{Add Figure}

Furthermore, the inclusion of positional information introduces a novel type of error. Specifically, since the robot behavior is conditioned by the bounding box, any error in its prediction can cause the robot to move incorrectly (Figure \ref{fig:error_propagation}). This error is significant, as in the Pick-Place task, the metric ``Place Wrong with Correct Object" reaches 11.25\%, and for the Nut-Assembly task, the same metric averages 22.22\%.
\input{figures/ch3/error_propagation.tex}

To address this issue, the Double-Control Module architecture has been proposed (Section \ref{sec:ocpl_architecture_dcm}), with the corresponding results presented in Section \ref{sec:ocpl_results_dcm}.

\paragraph*{Multi-task multi-variation scenario}\mbox{}\\
As in the previous paragraph, an evaluation of the two baseline methods was also conducted in the multi-task setting. The results are summarized in Table \ref{table:occp_multi_task_baseline_res}. The same general trends and behaviors observed in the single-task scenario are present here as well. Specifically, both baselines demonstrate the ability to produce reasonable trajectories that allow the robot to complete the task, though they manipulate the wrong object.

Furthermore, when comparing the results from Table \ref{table:occp_single_task_baseline_res} with those in Table \ref{table:occp_multi_task_baseline_res}, it is evident that the success rate decreases across all methods in the more complex multi-task setting. This highlights a potential issue with task balancing during the learning process.
\input{tables/ch3/baseline_multi_task.tex}

After evaluating the baseline, the proposed MOSAIC-CTOD was tested, using the same variations as in the previous section. Table \ref{table:ctod_multi_task_performance} summarizes the results obtained with the inclusion of positional information. Compared to the baseline, a general improvement is observed. However, caution is required when training the system in a multi-task setting. Specifically, when comparing the single-task performance (Table \ref{table:ctod_single_task}) to the multi-task performance, there is a noticeable drop in success rates for the same tasks. This decline is particularly evident in the system's ability to execute the "pick" primitive, especially when the nut object is involved. This observation underscores the importance of incorporating regularization techniques during multi-task learning to manage the varying complexities of different tasks.
\input{tables/ch3/ctod_multi_task.tex}

\subsubsection{Double control modules}
In this section the results obtained with the Double Control Module (Section \ref{sec:ocpl_architecture_dcm}) are going to be discussed.
\label{sec:ocpl_results_dcm}
\paragraph*{Single-task multi-variation scenario}\mbox{}\\
As discussed in Section \ref{sec:ocpl_architecture_dcm}, the introduction of the Double Control Module (DCM) was motivated by the need to reduce errors associated with incorrect object placement. These errors arise from inaccurate bounding-box predictions, which can lead to error propagation. 

To address this issue, the architecture of the Double Control Module evolved through incremental design iterations and validation steps.
Specifically, the process started by observing that the positional information given by the bouding-box is usefull only during the reaching phase, while it becomes useless after it. For this reason, the training of the MOSAIC-CTOD has been changed, setting to zero the bounding-box after the picking. Then, observing the obtained results and the error cases, the Double Control Module has been realized.

\input{tables/ch3/double_policy_single_task.tex}
Table \ref{table:double_policy_single_task} summarizes the obtained results, from which several important considerations can be made.

Firstly, it is noteworthy that removing the bounding box after picking reduces the error percentage for the \textit{Place Wrong Correct Object} category to 0.00\%, confirming the earlier observation regarding the noisy nature of the predicted bounding box after the picking phase. However, this modification alone does not lead to a general improvement in the overall success rate. In fact, the \textit{MOSAIC-CTOD (no-bb after pick)} model has a lower picking rate. This occurs because the control module issues the closing command too early, creating an out-of-distribution sample, which drives the robot into a novel state that was not encountered during training, making it unable to complete the task (Figure \ref{fig:error_no_bb_after_pick}).

\input{figures/ch3/error_no_bb_after_pick.tex}
% \smalltodo{add figure}

Regarding the performance of the proposed \textit{MOSAIC-COD} module, it is notable that it achieves the highest success rate in 3 out of 4 tasks. Specifically, for tasks prone to placing the correct object in the wrong position, such as Pick-Place and Nut-Assembly, this type of error is eliminated, resulting in an overall improvement in the success rate.

Moreover, a novel variant of the MOSAIC baseline, \textit{MOSAIC-DP}, has been implemented. This model follows the classic MOSAIC architecture proposed in \cite{mandi2022towards_more_generalizable_one_shot} but is equipped with two control modules: one for the reaching primitive and another for the primitive used in the final part of the task (i.e., placing, assembly, stacking, or pushing, respectively). 

It is important to note that the performance of this variation is very similar to the original MOSAIC baseline, even though the control problem is simplified by splitting it into two phases corresponding to different primitives. Specifically, the most significant error in this case also stems from manipulating the wrong object. The success rates with the wrong object are 54.38\%, 46.67\%, 46.67\%, and 7.59\% for the Pick-Place, Nut-Assembly, Stack-Block, and Press-Button tasks, respectively. 

This further supports the central thesis, which suggests that the end-to-end architecture struggles to create an optimal embedding that addresses both cognitive and control tasks effectively.

\paragraph*{Multi-task multi-variation scenario}\mbox{}\\
\input{tables/ch3/double_policy_multi_task.tex}
Given the results and observations from the previous section, the MOSAIC-COD module is directly compared to the baselines MOSAIC and MOSAIC-CTOD in the Multi-Task setting. Table \ref{table:cod_multi_task_performance} summarizes the results. As can be seen, the use of specialized models trained for the two task phases, reaching and placing, leads to a system that consistently picks the target object. This improvement is particularly evident in the more complex tasks, such as Pick-Place and Nut-Assembly. The enhanced picking rate demonstrates that having accurate information about the target object position enables correct target acquisition, while the presence of two control modules allows for training specific controllers for simpler primitives.

However, despite the improvements observed in Pick-Place and Nut-Assembly, MOSAIC-COD has the lowest overall success rate. This can be attributed to two main factors. First, the Press-Button task is substantially different from the other three tasks. Unlike the others, it does not involve pick-and-place primitives, making it an out-of-distribution task. Second, the instability of the bounding boxes produced can lead to undesirable behaviors, such as sudden movements or freezing.
% \smalltodo{add figure}

\subsubsection{Proprioceptive state and Generalization tests}
\input{figures/ch3/generalization_dataset.tex}

\input{figures/ch3/end_to_end_vs_modular_proprioceptive.tex}
In this section, additional experiments are described, focusing on two key objectives.

The first set of experiments aims to determine whether incorporating proprioceptive information can enhance the system's robustness. This is particularly important for tasks requiring fine manipulation, such as the Nut-Assembly task, where the goal is to reduce errors during the assembly phase, specifically avoiding instances where the nut hits the peg.

The second set of experiments explores the generalization capabilities of the proposed system. Specifically, the goal is to assess whether the system can generalize to previously unseen task variations. To evaluate this, the system is trained on a subset of task variations selected as follows: for a set of variations involving a specific target object (e.g., a green box), one variation is excluded (e.g., placing the box into the first bin). However, in other sets involving different objects, the variation that requires placing the object into the first bin is retained. This setup allows for testing how well the system can transfer knowledge across different variations. By doing so, it becomes possible to evaluate whether the system can achieve robust performance with less training data, eliminating the need to collect every possible variation for each object (Figure \ref{fig:generalization_dataset}).
% \smalltodo{add figure}

\input{tables/ch3/proprioceptive.tex}
\paragraph*{Proprioceptive information}\mbox{}\\
The proprioceptive information selected for the four tasks considered includes the joint positions, $joints_{pos} \in \mathcal{R}^{6}$ and the gripper state, $gripper_{state} \in \left[ 0, 1 \right]$. This vector of elements, $x^{prop}$, is provided as input directly to the Control Module, as shown in Figure \ref{fig:end_to_end_vs_modular_proprioceptive}. 
% \smalltodo{add figure}

Specifically, for each baseline method, \textit{MOSAIC}, \textit{MOSAIC-CTOD}, and \textit{MOSAIC-COD}, a version of the model incorporating proprioceptive information was trained. Table \ref{table:proprioceptive} presents the success rates for both the Single-Task and Multi-Task scenarios. 

It is important to note that for 3 out of 4 tasks, the best performance is achieved by combining the Double-Policy approach with proprioceptive information, effectively solving the manipulation tasks of Pick-Place, Nut-Assembly, and Stack-Block in a robust manner. The greatest improvement is seen in the Nut-Assembly task, where the proprioceptive information resolves issues related to collisions and robot freezing.

However, this improvement is not observed in the Press-Button task, where a 35\% drop in success rate is seen, even with the \textit{MOSAIC} baseline. In this task, the main failure cases are related to unstable robot behavior. Additionally, in variations focused on object orientation, the robot often gets stuck when correctly approaching the button.

Notably, the same behavior is not observed in the Multi-Task scenario. In fact, the highest performance is achieved by methods that exclude proprioceptive information. Specifically, the introduction of proprioceptive data appears to exacerbate the imbalance between tasks, hindering the system from effectively utilizing this additional information during testing, which leads to instability. 

For example, in the case of the MOSAIC-CTOD-P module, the robot successfully picks the target object only 58.87\% of the time. This occurs because the closing command is sent too early, relative to the object position. Furthermore, the success rate drops further to 38.14\%, as the robot, despite reaching the target peg, collides with it, an issue where proprioceptive information should theoretically provide assistance, especially since the pegs are fixed.

This instability is most evident in the Stack-Block task, where the success rate falls to 22.77\% for the MOSAIC-COD-P module, despite the robot picking the target object with an average rate of 80.00\%. The errors in this case are due to the object being dropped during stacking, caused by imprecise placement, as well as instances where the robot becomes completely stuck.

These results highlight the need for a balanced learning procedure in the context of Multi-Task Learning, as discussed earlier in Section \ref{sec:ocpl_results_scm}.

\input{tables/ch3/generalization.tex}
\paragraph*{Generalization}\mbox{}\\
Regarding the generalization tests, we evaluated only the three tasks where the previously explained variation selection was applicable. Specifically, the following variations were removed for each task (Figure \ref{fig:generalization_dataset}):

\begin{itemize}
    \item \textbf{Pick-Place}: Variations 1, 6, 11, and 16 were excluded.
    \item \textbf{Nut-Assembly}: Variations 1, 5, and 9 were excluded.
    \item \textbf{Stack-Block}: Variations 1, 4, and 6 were excluded.
\end{itemize}

The models were trained on the remaining variations and tested on the excluded ones following the same procedure.

Table \ref{table:generalization} summarizes the success rates obtained for both the Single-Task and Multi-Task settings. Notably, with the introduction of the CTOD and COD modules, the system consistently reaches the correct target object in unseen variations. Similarly, the robot is able to pick and complete tasks, outperforming the MOSAIC baseline across all tested tasks.

This is a promising result, as it demonstrates that the system can effectively share knowledge across different variations, enabling robust training with less data.


