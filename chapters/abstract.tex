\chapter*{Abstract}
% 5 PAGINE E UN PO
\label{ch:abstract}
Robot technology is one of the pillars of modern society. Advances in information, electronic, and mechanical fields enable us to build and program machines to perform tasks in very different contexts, such as industry, surgery, and space missions.
\newline Specifically, in manufacturing, robots are mainly used to perform repetitive and unhealthy works like assembly, welding and material handling, thanks to their mechanical robustness and ability to repeatedly perform the same movements with high accuracy and precision.

While in the early day, robot systems were constrained in isolated and known environments. Over the past few decades, robots have been asked to solve tasks in dynamic and unknown/partially known environments, where they must \textbf{coexist} and \textbf{cooperate} with humans, while  solving different \textbf{dynamic} tasks \cite{bini2023multi} (e.g. pick a requested object, whose position is not known a priori). 

In this scenario, the desired characteristics of such robotic systems are:
\begin{enumerate*}[label=\textbf{(\alph*)}]
\item \textbf{Adaptability to new conditions}, i.e., the system must be able to easily adapt to dynamic changes in system and environmental conditions, performing \textit{``intelligent" behaviors} to handle these new scenarios and solve the desired task;
\item \textbf{Adaptability to new tasks}, i.e., the system must be able to easily adapt to both new variations of a known task and completely new tasks by exploiting experience to infer actions and solve them;
% \item \textbf{Reliability}, i.e., the proposed system must be reliable in terms of success rate (tasks must be solved with a success rate that is reasonable for a real-world application), and safety (actions must not harm the environment, people, or the robot itself);
% \item \textbf{Computational efficiency}, i.e., the system must meet all the constraints above and run in real-time on real-world robot platforms as efficiently as possible.
\end{enumerate*}

These requirements, can be challenging to achieve with traditional robot programming techniques based on hand-written policies and control methods. These conventional techniques often require a meticulous analysis of process dynamics, the construction of an analytical model, and the derivation of a control law that meets specific design criteria. This design process is tedious and time-consuming, particularly when high-level perception systems (e.g., cameras, microphones, motion sensors) are used to infer the state of the environment (such as the unknown position of a desired object relative to the end-effector) and the intentions of the human operator.

% In questo caso la funzione di controllo viene appresa dai dati, nello specifico, nel primo caso 
In contrast, significant advancements have been made by leveraging \textit{learning techniques}, where the control policy is learned from data. This data can be generated either by \textbf{agent experience} \cite{sutton2018reinforcement} or by \textbf{expert demonstration} \cite{osa2018algorithmic}. In the case of agent experience, there is a trial-and-error procedure where the control policy generates actions executed by an agent, which interacts with the environment. The parameters are then tuned according to the effectiveness of the actions, based on their impact on the environment relative to the task to be solved. In the case of expert demonstration, the control policy parameters are directly tuned using a dataset containing examples of task execution. The goal is to replicate the tasks observed in the dataset.

% In questo caso, la policy di controllo non è addestrata per eseguire un singolo task (pick an object), con l'obiettivo di generalizzare rispetto a diversi oggetti e diverse condizioni iniziali. Ma è addestrata per eseguire diverse variazioni di uno specifico task (e.g., pick an object with different possible placing location) o addirittura task  diversi tra di loro (e.g., una singola policy di controllo che risolve sia il problema del pick-place sia problemi di assemblaggio), con l'obiettivo di generalizzare rispetto agli oggetti che vengono manipolati, le condizioni iniziali e rispetto ai task stessi. Questo significa che, sfruttando l'ipotesi di knowledge-sharing possiamo ottenere un sistema in grado di risolvere nuove variazioni.  
Specifically this thesis is framed in the context of \textit{Learning from Demonstration} (LfD), a learning approach based on expert demonstration. According to the requirements of adaptability the thesis focus on a specific aspect of LfD named \textit{Multi-Task LfD}. In this case, the control policy is not trained to execute a single task (e.g., picking an object) with the goal of generalizing across different objects and initial conditions \cite{zhang2018deep_vr_teleoperation,mandlekar2022matters}. Instead, it is trained to handle various variations of a specific task (e.g., picking an object from different possible locations) \cite{dasari2021transformers_one_shot} or even entirely different tasks (e.g., a single control policy that solves both picking and placing tasks as well as assembly tasks) \cite{brohan2022rt,mandi2022towards_more_generalizable_one_shot}. The goal is to generalize not only with respect to the objects being manipulated and the initial conditions but also with respect to the tasks themselves. This means that by leveraging the knowledge-sharing hypothesis, a system capable of solving new variations can be achieved.

In this scenario, the learning procedure is much more challenging because we need to include and define the \textbf{conditioning signal} (i.e., the signal that informs the policy about the task to execute, the object to manipulate, and the target placing location). Additionally, the environment can contain \textbf{multiple distractor objects} (e.g., objects that can potentially be manipulated but are not of interest for a given task variation). 

Regarding the conditioning signal, there are at least two intuitive approaches. The first is through a natural language description of the task to be executed \cite{stepputtis2020language,mees2022calvin,brohan2022rt}, and the second is through a video demonstration \cite{dasari2021transformers_one_shot,mandi2022towards_more_generalizable_one_shot}. 
In the former, the task is described using phrases that specify the task details, such as ``Pick the red box and place it into the first bin". Given in input the phrase, the system must be able to infer the intent of the task (i.e., the pick-place operation) and the object of interest (e.g., red-box for picking and first bin for placing), and correlate this information with the environment and robot state to effectively control the robot.
In the latter, another agent (either a robot or a human operator) performs the task in a different environment configuration, records this execution, and provides the video as input to the control policy. The control policy must then infer the intent from the video (i.e., the task to be performed, the object to be manipulated, and the final state) and control the robot to complete the task according to the agent's state, the environment's state, and the commanded task.
Inspired by how humans can learn to replicate tasks by simply observing their execution, the main goal of this thesis is to develop a system capable of replicating tasks shown in a video demonstration. This involves addressing challenges related to extracting task-relevant information from the video, such as identifying the manipulated object and its final position.

% Per quanto riguarda il problema legato alla presenza degli oggetti distrattori, in generale questi sono oggetti che non vengono mai considerati in operazioni di manipolazione, semplificando di molto il problema. Però nel contesto proposto in questa tesi il problema è ulteriormente enfatizzato dal fatto che il significato semantico di oggetto di interesse o distrattore associato agli oggetti presenti nella scena è definito a run-time dal comando stesso. Questo significa che se la configurazione iniziale è composta da 4 oggetti (e.g., 4 box di colore diverso), sulla base del comando dato al robot un determinato oggetto può diventare o meno di interesse. 
Regarding the issue of distractor objects, these are generally items that are not considered in manipulation operations, which simplifies the problem significantly. However, in the context proposed in this thesis, the problem is further complicated by the fact that the semantic meaning of an object of interest or a distractor is defined at run-time by the command itself. This means that if the initial configuration consists of four objects (e.g., four boxes of different colors), a specific object may or may not be of interest based on the command given to the robot.

The main contribution of this thesis is addressing the issue of distractor objects. Specifically, it was observed that a significant problem with the methods proposed in the literature is that while the learned control policy can generate valid trajectories, allowing the robot to reach, pick, and place objects, it often manipulates the wrong object. To address this problem, two main considerations have been made:

\begin{enumerate*}[label=\textbf{(\arabic*)}]
\item The architectures proposed in current literature predominantly consist of end-to-end architectures, which translate high-level inputs such as images into corresponding actions. Consequently, the model must acquire an implicit representation capable of encoding both the task objective and the current state of the environment, including the location of the target object;
\item The learning procedure optimizes a metric that is not directly linked to task success but rather aims to replicate actions similar to those of the expert, on average.
\end{enumerate*}

These two aspects can lead to a control policy that is not able to effectively guide the robot toward the target object. Indeed, it was observed that one of the critical points during trajectory execution is the first steps. Small errors in these initial steps can result in reaching and consequently picking the wrong object.

Based on these considerations, this thesis evaluates the possibility of developing a system that explicitly reasons about the objects of interest (e.g., target object and placing location). The control module is then directly informed with low-level information, such as the position of the target object.

To perform this explicit reasoning, a \textit{Conditioned Object Detector} (COD) has been developed. This module, given the video demonstration and the current agent observation as input, predicts the class-agnostic bounding box related to the target object and the final placing location. This low-level positional information is then provided to the control module, which predicts the actions to perform.

The learning procedure is then divided into two steps. The first step involves training the \textit{Conditioned Object Detector} (COD) module, which focuses on explicitly solving cognitive tasks, such as detecting regions of interest represented by the object to be manipulated and its final location. The second step involves training the \textit{Object Conditioned Control Policy} (OCCP), which focuses on solving the control problem using low-level positional information that can be easily mapped into the corresponding actions.

The final system has been tested in both \textbf{multi-variation single-task} scenarios and \textbf{multi-variation multi-task} scenarios. Specifically, the system was evaluated on four different   simulated tasks: Pick-Place, Nut-Assembly, Stack-Block, and Button-Press. Each task had different variations based on the manipulated object and the final state. While the tasks share common properties, they also have specific characteristics. For example, the Nut-Assembly task involves contact-rich, precise manipulation, whereas Pick-Place can be solved in a much rougher manner.

Overall, the proposed methods demonstrated very promising behaviors and a general improvement over baseline methods that do not include object-related reasoning. This shows that solving manipulation tasks with an object-oriented approach can be an effective paradigm for LfD problems. Additionally, this approach provides interpretable information to the end user, as the predicted bounding boxes can be interpreted as the locations where the robot will move.

In conclusion, the proposed method was tested also in a real-world environment, where the complexity of the problem is heightened by the presence of less and noisy data collected through teleoperation. Even under these challenging conditions, the proposed method demonstrated its effectiveness in addressing both the cognitive and control problems. This confirms that the object prior can be successfully applied in real-world scenarios, enabling the development of a reliable system despite limited and noisy trajectory data.
