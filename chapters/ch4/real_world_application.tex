\chapter{Experimental validation in real-world scenario}
\label{ch:real_world_application}
This chapter details the validation of the proposed methods in a real world scenario. Specifically, Section~\ref{sec:real_world_exp_setting} describes the experimental setup. Section~\ref{sec:real_world_dataset} discusses the dataset used to train the system. Finally, Section~\ref{sec:real_results} presents the results obtained.

\input{chapters/ch4/experimental_setting.tex}
\input{chapters/ch4/dataset.tex}
\input{chapters/ch4/results.tex}

\section{Conclusion}
In conclusion, this chapter presented the experimental validation of the proposed methods in a real-world scenario. Both the proposed detectors and control policies were tested in a single-task multi-variation scenario.

Regarding the conditioned object detectors, it was observed that the system successfully identified the target object even when the video demonstration was provided by a simulated robot, which had a different visual appearance compared to the real robot. This highlights the strong potential of the proposed method to generalize across different demonstrators and environments, such as human demonstrators. Generally, the patterns observed in the simulated environment were replicated in the real-world tests, where the system consistently identified the target object during the reaching phase but generated false positives during the manipulation and placing phases. However, the drop in precision was more pronounced in the real-world setting due to occlusions and inaccuracies in the automated bounding box generation process.

As for the control policies, the results demonstrated that the proposed architectures were able to successfully complete tasks in real-world scenarios. The object conditioned control policies consistently reached the target object, leading to successful task completion. Across all variations of the proposed method, an average reaching rate of $85.40\%$ was achieved, compared to $14.12\%$ for the MOSAIC baseline. This indicates that object priors can be effectively leveraged to simplify the control problem, resulting in a policy that consistently reaches the target object, even when using a dataset with low-quality demonstrations. In terms of overall success rate, the MOSAIC-COD module achieved the highest rate of $55.00\%$. While this may not seem particularly high, it is a promising result given the challenging nature of the dataset, which contains fewer and noisier trajectories compared to the simulated environment. This result becomes even more significant when compared to the MOSAIC baseline's success rate of $0.00\%$.

Generally speaking, the most critical error observed involves collisions with the target object. This type of error could be significantly reduced by integrating additional exteroceptive modalities, such as depth images from the gripper camera. Incorporating this data would enable the system to better detect the target object and avoid collisions during the picking phase, which is expected to result in a substantial improvement in the overall success rate.