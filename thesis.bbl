% Generated by IEEEtran.bst, version: 1.14 (2015/08/26)
\begin{thebibliography}{100}
\providecommand{\url}[1]{#1}
\csname url@samestyle\endcsname
\providecommand{\newblock}{\relax}
\providecommand{\bibinfo}[2]{#2}
\providecommand{\BIBentrySTDinterwordspacing}{\spaceskip=0pt\relax}
\providecommand{\BIBentryALTinterwordstretchfactor}{4}
\providecommand{\BIBentryALTinterwordspacing}{\spaceskip=\fontdimen2\font plus
\BIBentryALTinterwordstretchfactor\fontdimen3\font minus
  \fontdimen4\font\relax}
\providecommand{\BIBforeignlanguage}[2]{{%
\expandafter\ifx\csname l@#1\endcsname\relax
\typeout{** WARNING: IEEEtran.bst: No hyphenation pattern has been}%
\typeout{** loaded for the language `#1'. Using the pattern for}%
\typeout{** the default language instead.}%
\else
\language=\csname l@#1\endcsname
\fi
#2}}
\providecommand{\BIBdecl}{\relax}
\BIBdecl

\bibitem{bini2023multi}
S.~Bini, G.~Percannella, A.~Saggese, and M.~Vento, ``A multi-task network for
  speaker and command recognition in industrial environments,'' \emph{Pattern
  Recognition Letters}, vol. 176, pp. 62--68, 2023.

\bibitem{sutton2018reinforcement}
R.~S. Sutton and A.~G. Barto, \emph{Reinforcement learning: An
  introduction}.\hskip 1em plus 0.5em minus 0.4em\relax MIT press, 2018.

\bibitem{osa2018algorithmic}
T.~Osa, J.~Pajarinen, G.~Neumann, J.~A. Bagnell, P.~Abbeel, J.~Peters
  \emph{et~al.}, ``An algorithmic perspective on imitation learning,''
  \emph{Foundations and Trends{\textregistered} in Robotics}, vol.~7, no. 1-2,
  pp. 1--179, 2018.

\bibitem{zhang2018deep_vr_teleoperation}
T.~Zhang, Z.~McCarthy, O.~Jow, D.~Lee, X.~Chen, K.~Goldberg, and P.~Abbeel,
  ``Deep imitation learning for complex manipulation tasks from virtual reality
  teleoperation,'' in \emph{2018 IEEE International Conference on Robotics and
  Automation (ICRA)}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2018, pp.
  5628--5635.

\bibitem{mandlekar2022matters}
A.~Mandlekar, D.~Xu, J.~Wong, S.~Nasiriany, C.~Wang, R.~Kulkarni, L.~Fei-Fei,
  S.~Savarese, Y.~Zhu, and R.~Mart{\'\i}n-Mart{\'\i}n, ``What matters in
  learning from offline human demonstrations for robot manipulation,'' in
  \emph{Conference on Robot Learning}.\hskip 1em plus 0.5em minus 0.4em\relax
  PMLR, 2022, pp. 1678--1690.

\bibitem{dasari2021transformers_one_shot}
S.~Dasari and A.~Gupta, ``Transformers for one-shot visual imitation,'' in
  \emph{Conference on Robot Learning}.\hskip 1em plus 0.5em minus 0.4em\relax
  PMLR, 2021, pp. 2071--2084.

\bibitem{brohan2022rt}
\BIBentryALTinterwordspacing
A.~Brohan, N.~Brown, J.~Carbajal, Y.~Chebotar, J.~Dabis, C.~Finn,
  K.~Gopalakrishnan, K.~Hausman, A.~Herzog, J.~Hsu, J.~Ibarz, B.~Ichter,
  A.~Irpan, T.~Jackson, S.~Jesmonth, N.~J. Joshi, R.~Julian, D.~Kalashnikov,
  Y.~Kuang, I.~Leal, K.~Lee, S.~Levine, Y.~Lu, U.~Malla, D.~Manjunath,
  I.~Mordatch, O.~Nachum, C.~Parada, J.~Peralta, E.~Perez, K.~Pertsch,
  J.~Quiambao, K.~Rao, M.~S. Ryoo, G.~Salazar, P.~R. Sanketi, K.~Sayed,
  J.~Singh, S.~Sontakke, A.~Stone, C.~Tan, H.~T. Tran, V.~Vanhoucke, S.~Vega,
  Q.~Vuong, F.~Xia, T.~Xiao, P.~Xu, S.~Xu, T.~Yu, and B.~Zitkovich, ``{RT-1:}
  robotics transformer for real-world control at scale,'' in \emph{Robotics:
  Science and Systems XIX, Daegu, Republic of Korea, July 10-14, 2023}, K.~E.
  Bekris, K.~Hauser, S.~L. Herbert, and J.~Yu, Eds., 2023. [Online]. Available:
  \url{https://doi.org/10.15607/RSS.2023.XIX.025}
\BIBentrySTDinterwordspacing

\bibitem{mandi2022towards_more_generalizable_one_shot}
Z.~Mandi, F.~Liu, K.~Lee, and P.~Abbeel, ``Towards more generalizable one-shot
  visual imitation learning,'' in \emph{2022 International Conference on
  Robotics and Automation (ICRA)}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE,
  2022, pp. 2434--2444.

\bibitem{stepputtis2020language}
S.~Stepputtis, J.~Campbell, M.~Phielipp, S.~Lee, C.~Baral, and H.~Ben~Amor,
  ``Language-conditioned imitation learning for robot manipulation tasks,''
  \emph{Advances in Neural Information Processing Systems}, vol.~33, pp.
  13\,139--13\,150, 2020.

\bibitem{mees2022calvin}
O.~Mees, L.~Hermann, E.~Rosete-Beas, and W.~Burgard, ``Calvin: A benchmark for
  language-conditioned policy learning for long-horizon robot manipulation
  tasks,'' \emph{IEEE Robotics and Automation Letters (RA-L)}, vol.~7, no.~3,
  pp. 7327--7334, 2022.

\bibitem{jang2022bc_z}
E.~Jang, A.~Irpan, M.~Khansari, D.~Kappler, F.~Ebert, C.~Lynch, S.~Levine, and
  C.~Finn, ``Bc-z: Zero-shot task generalization with robotic imitation
  learning,'' in \emph{Conference on Robot Learning}.\hskip 1em plus 0.5em
  minus 0.4em\relax PMLR, 2022, pp. 991--1002.

\bibitem{yu2018daml}
T.~Yu, C.~Finn, S.~Dasari, A.~Xie, T.~Zhang, P.~Abbeel, and S.~Levine,
  ``One-shot imitation from observing humans via domain-adaptive
  meta-learning,'' in \emph{Proceedings of Robotics: Science and Systems},
  Pittsburgh, Pennsylvania, June 2018.

\bibitem{zare2024survey}
M.~Zare, P.~M. Kebria, A.~Khosravi, and S.~Nahavandi, ``A survey of imitation
  learning: Algorithms, recent developments, and challenges,'' \emph{IEEE
  Transactions on Cybernetics}, 2024.

\bibitem{james2018task_embedded}
\BIBentryALTinterwordspacing
S.~James, M.~Bloesch, and A.~J. Davison, ``Task-embedded control networks for
  few-shot imitation learning,'' in \emph{2nd Annual Conference on Robot
  Learning, CoRL 2018, Z{\"{u}}rich, Switzerland, 29-31 October 2018,
  Proceedings}, ser. Proceedings of Machine Learning Research, vol.~87.\hskip
  1em plus 0.5em minus 0.4em\relax {PMLR}, 2018, pp. 783--795. [Online].
  Available: \url{http://proceedings.mlr.press/v87/james18a.html}
\BIBentrySTDinterwordspacing

\bibitem{shridhar2023perceiver}
M.~Shridhar, L.~Manuelli, and D.~Fox, ``Perceiver-actor: A multi-task
  transformer for robotic manipulation,'' in \emph{Conference on Robot
  Learning}.\hskip 1em plus 0.5em minus 0.4em\relax PMLR, 2023, pp. 785--799.

\bibitem{fang2019survey}
B.~Fang, S.~Jia, D.~Guo, M.~Xu, S.~Wen, and F.~Sun, ``Survey of imitation
  learning for robotic manipulation,'' \emph{International Journal of
  Intelligent Robotics and Applications}, vol.~3, no.~4, pp. 362--369, 2019.

\bibitem{kroemer2021review_robot_learning}
O.~Kroemer, S.~Niekum, and G.~Konidaris, ``A review of robot learning for
  manipulation: Challenges, representations, and algorithms,'' \emph{The
  Journal of Machine Learning Research}, vol.~22, no.~1, pp. 1395--1476, 2021.

\bibitem{johns2021coarse_to_fine}
E.~Johns, ``Coarse-to-fine imitation learning: Robot manipulation from a single
  demonstration,'' in \emph{2021 IEEE International Conference on Robotics and
  Automation (ICRA)}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2021, pp.
  4613--4619.

\bibitem{caccavale2019kinesthetic}
R.~Caccavale, M.~Saveriano, A.~Finzi, and D.~Lee, ``Kinesthetic teaching and
  attentional supervision of structured tasks in human--robot interaction,''
  \emph{Autonomous Robots}, vol.~43, no.~6, pp. 1291--1307, 2019.

\bibitem{mandlekar2018roboturk}
A.~Mandlekar, Y.~Zhu, A.~Garg, J.~Booher, M.~Spero, A.~Tung, J.~Gao, J.~Emmons,
  A.~Gupta, E.~Orbay \emph{et~al.}, ``Roboturk: A crowdsourcing platform for
  robotic skill learning through imitation,'' in \emph{Conference on Robot
  Learning}.\hskip 1em plus 0.5em minus 0.4em\relax PMLR, 2018, pp. 879--893.

\bibitem{ebert22Bridge}
F.~Ebert, Y.~Yang, K.~Schmeckpeper, B.~Bucher, G.~Georgakis, K.~Daniilidis,
  C.~Finn, and S.~Levine, ``{Bridge Data: Boosting Generalization of Robotic
  Skills with Cross-Domain Datasets},'' in \emph{Proceedings of Robotics:
  Science and Systems}, New York City, NY, USA, June 2022.

\bibitem{mandlekar2023mimicgen}
A.~Mandlekar, S.~Nasiriany, B.~Wen, I.~Akinola, Y.~Narang, L.~Fan, Y.~Zhu, and
  D.~Fox, ``Mimicgen: A data generation system for scalable robot learning
  using human demonstrations,'' in \emph{Conference on Robot Learning}.\hskip
  1em plus 0.5em minus 0.4em\relax PMLR, 2023, pp. 1820--1864.

\bibitem{dasari2020robonet}
S.~Dasari, F.~Ebert, S.~Tian, S.~Nair, B.~Bucher, K.~Schmeckpeper, S.~Singh,
  S.~Levine, and C.~Finn, ``Robonet: Large-scale multi-robot learning,'' in
  \emph{Conference on Robot Learning}.\hskip 1em plus 0.5em minus 0.4em\relax
  PMLR, 2020, pp. 885--897.

\bibitem{chang2023one}
M.~Chang and S.~Gupta, ``One-shot visual imitation via attributed waypoints and
  demonstration augmentation,'' in \emph{2023 IEEE International Conference on
  Robotics and Automation (ICRA)}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE,
  2023, pp. 5055--5062.

\bibitem{lee2011incremental}
D.~Lee and C.~Ott, ``Incremental kinesthetic teaching of motion primitives
  using the motion refinement tube,'' \emph{Autonomous Robots}, vol.~31, pp.
  115--131, 2011.

\bibitem{saveriano2015incremental}
M.~Saveriano, S.-i. An, and D.~Lee, ``Incremental kinesthetic teaching of
  end-effector and null-space motion primitives,'' in \emph{2015 IEEE
  International Conference on Robotics and Automation (ICRA)}.\hskip 1em plus
  0.5em minus 0.4em\relax IEEE, 2015, pp. 3570--3575.

\bibitem{mandlekar2019scaling}
A.~Mandlekar, J.~Booher, M.~Spero, A.~Tung, A.~Gupta, Y.~Zhu, A.~Garg,
  S.~Savarese, and L.~Fei-Fei, ``Scaling robot supervision to hundreds of hours
  with roboturk: Robotic manipulation dataset through human reasoning and
  dexterity,'' in \emph{2019 IEEE/RSJ International Conference on Intelligent
  Robots and Systems (IROS)}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE,
  2019, pp. 1048--1055.

\bibitem{cyberglove}
\BIBentryALTinterwordspacing
C.~Systems, ``Cyberforce.'' [Online]. Available:
  \url{http://www.cyberglovesystems.com/cyberforce}
\BIBentrySTDinterwordspacing

\bibitem{touch}
\BIBentryALTinterwordspacing
D.~Systems, ``Touch.'' [Online]. Available:
  \url{https://it.3dsystems.com/haptics-devices/touch}
\BIBentrySTDinterwordspacing

\bibitem{zhu2020robosuite}
Y.~Zhu, J.~Wong, A.~Mandlekar, R.~Mart{\'\i}n-Mart{\'\i}n, A.~Joshi,
  S.~Nasiriany, and Y.~Zhu, ``robosuite: A modular simulation framework and
  benchmark for robot learning,'' \emph{arXiv preprint arXiv:2009.12293}, 2020.

\bibitem{liu2019_mirroring_without_overimitation}
H.~Liu, C.~Zhang, Y.~Zhu, C.~Jiang, and S.-C. Zhu, ``Mirroring without
  overimitation: Learning functionally equivalent manipulation actions,''
  \emph{Proceedings of the AAAI Conference on Artificial Intelligence},
  vol.~33, no.~01, pp. 8025--8033, Jul. 2019.

\bibitem{smith2019avid}
L.~Smith, N.~Dhawan, M.~Zhang, P.~Abbeel, and S.~Levine, ``{AVID: Learning
  Multi-Stage Tasks via Pixel-Level Translation of Human Videos},'' in
  \emph{Proceedings of Robotics: Science and Systems}, Corvalis, Oregon, USA,
  July 2020.

\bibitem{nakaoka2007learning}
S.~Nakaoka, A.~Nakazawa, F.~Kanehiro, K.~Kaneko, M.~Morisawa, H.~Hirukawa, and
  K.~Ikeuchi, ``Learning from observation paradigm: Leg task models for
  enabling a biped humanoid robot to imitate human dances,'' \emph{The
  International Journal of Robotics Research}, vol.~26, no.~8, pp. 829--844,
  2007.

\bibitem{liu2017glove_force}
H.~Liu, X.~Xie, M.~Millar, M.~Edmonds, F.~Gao, Y.~Zhu, V.~J. Santos,
  B.~Rothrock, and S.-C. Zhu, ``A glove-based system for studying hand-object
  manipulation via joint pose and force sensing,'' in \emph{2017 IEEE/RSJ
  International Conference on Intelligent Robots and Systems (IROS)}.\hskip 1em
  plus 0.5em minus 0.4em\relax IEEE, 2017, pp. 6617--6624.

\bibitem{torabi2019recent_advances_lfo}
\BIBentryALTinterwordspacing
F.~Torabi, G.~Warnell, and P.~Stone, ``Recent advances in imitation learning
  from observation,'' in \emph{Proceedings of the Twenty-Eighth International
  Joint Conference on Artificial Intelligence, {IJCAI-19}}.\hskip 1em plus
  0.5em minus 0.4em\relax International Joint Conferences on Artificial
  Intelligence Organization, 7 2019, pp. 6325--6331. [Online]. Available:
  \url{https://doi.org/10.24963/ijcai.2019/882}
\BIBentrySTDinterwordspacing

\bibitem{xiong2021learning_by_watching}
H.~Xiong, Q.~Li, Y.-C. Chen, H.~Bharadhwaj, S.~Sinha, and A.~Garg, ``Learning
  by watching: Physical imitation of manipulation skills from human videos,''
  in \emph{2021 IEEE/RSJ International Conference on Intelligent Robots and
  Systems (IROS)}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2021, pp.
  7827--7834.

\bibitem{wang2023mimicplay}
C.~Wang, L.~Fan, J.~Sun, R.~Zhang, L.~Fei-Fei, D.~Xu, Y.~Zhu, and
  A.~Anandkumar, ``Mimicplay: Long-horizon imitation learning by watching human
  play,'' in \emph{Conference on Robot Learning}.\hskip 1em plus 0.5em minus
  0.4em\relax PMLR, 2023, pp. 201--221.

\bibitem{qian2024contrast}
Z.~Qian, M.~You, H.~Zhou, X.~Xu, H.~Fu, J.~Xue, and B.~He, \emph{IEEE
  Transactions on Automation Science and Engineering}, 2024.

\bibitem{kaelbling1996reinforcement_survey}
L.~P. Kaelbling, M.~L. Littman, and A.~W. Moore, ``Reinforcement learning: A
  survey,'' \emph{Journal of artificial intelligence research}, vol.~4, pp.
  237--285, 1996.

\bibitem{argall2009robot_learning_from_demonstration}
B.~D. Argall, S.~Chernova, M.~Veloso, and B.~Browning, ``A survey of robot
  learning from demonstration,'' \emph{Robotics and autonomous systems},
  vol.~57, no.~5, pp. 469--483, 2009.

\bibitem{hussein2017imitation_learning_survey}
A.~Hussein, M.~M. Gaber, E.~Elyan, and C.~Jayne, ``Imitation learning: A survey
  of learning methods,'' \emph{ACM Computing Surveys (CSUR)}, vol.~50, no.~2,
  pp. 1--35, 2017.

\bibitem{zheng2021imitation_progress_taxonomies_opportunities}
B.~Zheng, S.~Verma, J.~Zhou, I.~Tsang, and F.~Chen, ``Imitation learning:
  Progress, taxonomies and opportunities,'' \emph{arXiv preprint
  arXiv:2106.12177}, 2021.

\bibitem{pomerleau1988alvinn}
D.~A. Pomerleau, ``Alvinn: An autonomous land vehicle in a neural network,''
  \emph{Advances in neural information processing systems}, vol.~1, 1988.

\bibitem{ijspeert2002learning}
A.~Ijspeert, J.~Nakanishi, and S.~Schaal, ``Learning attractor landscapes for
  learning motor primitives,'' \emph{Advances in neural information processing
  systems}, vol.~15, 2002.

\bibitem{ijspeert2013dynamical}
A.~J. Ijspeert, J.~Nakanishi, H.~Hoffmann, P.~Pastor, and S.~Schaal,
  ``Dynamical movement primitives: learning attractor models for motor
  behaviors,'' \emph{Neural computation}, vol.~25, no.~2, pp. 328--373, 2013.

\bibitem{si2023composite}
W.~Si, N.~Wang, and C.~Yang, ``Composite dynamic movement primitives based on
  neural networks for human--robot skill transfer,'' \emph{Neural Computing and
  Applications}, vol.~35, no.~32, pp. 23\,283--23\,293, 2023.

\bibitem{li2023human}
J.~Li, J.~Wang, S.~Wang, and C.~Yang, ``Human--robot skill transmission for
  mobile robot via learning by demonstration,'' \emph{Neural Computing and
  Applications}, vol.~35, no.~32, pp. 23\,441--23\,451, 2023.

\bibitem{fanger2016gaussian}
Y.~Fanger, J.~Umlauft, and S.~Hirche, ``Gaussian processes for dynamic movement
  primitives with application in knowledge-based cooperation,'' in \emph{2016
  IEEE/RSJ International Conference on Intelligent Robots and Systems
  (IROS)}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2016, pp. 3913--3919.

\bibitem{paraschos2013ProMPs}
A.~Paraschos, C.~Daniel, J.~R. Peters, and G.~Neumann, ``Probabilistic movement
  primitives,'' \emph{Advances in neural information processing systems},
  vol.~26, 2013.

\bibitem{saveriano2023dynamic}
M.~Saveriano, F.~J. Abu-Dakka, A.~Kramberger, and L.~Peternel, ``Dynamic
  movement primitives in robotics: A tutorial survey,'' \emph{The International
  Journal of Robotics Research}, vol.~42, no.~13, pp. 1133--1184, 2023.

\bibitem{zhou2019learning}
Y.~Zhou, J.~Gao, and T.~Asfour, ``Learning via-point movement primitives with
  inter-and extrapolation capabilities,'' in \emph{2019 IEEE/RSJ International
  Conference on Intelligent Robots and Systems (IROS)}.\hskip 1em plus 0.5em
  minus 0.4em\relax IEEE, 2019, pp. 4301--4308.

\bibitem{meier2011movement_primitive}
F.~Meier, E.~Theodorou, F.~Stulp, and S.~Schaal, ``Movement segmentation using
  a primitive library,'' in \emph{2011 IEEE/RSJ International Conference on
  Intelligent Robots and Systems}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE,
  2011, pp. 3407--3412.

\bibitem{agostini2020manipulation}
A.~Agostini, M.~Saveriano, D.~Lee, and J.~Piater, ``Manipulation planning using
  object-centered predicates and hierarchical decomposition of contextual
  actions,'' \emph{IEEE Robotics and Automation Letters}, vol.~5, no.~4, pp.
  5629--5636, 2020.

\bibitem{shafiullah2022behavior}
N.~M. Shafiullah, Z.~Cui, A.~A. Altanzaya, and L.~Pinto, ``Behavior
  transformers: Cloning $ k $ modes with one stone,'' \emph{Advances in neural
  information processing systems}, vol.~35, pp. 22\,955--22\,968, 2022.

\bibitem{nair2022r3m}
S.~Nair, A.~Rajeswaran, V.~Kumar, C.~Finn, and A.~Gupta, ``R3m: A universal
  visual representation for robot manipulation,'' \emph{arXiv preprint
  arXiv:2203.12601}, 2022.

\bibitem{cheng2023diffusion}
C.~Chi, S.~Feng, Y.~Du, Z.~Xu, E.~Cousineau, B.~C. Burchfiel, and S.~Song,
  ``{Diffusion Policy: Visuomotor Policy Learning via Action Diffusion},'' in
  \emph{Proceedings of Robotics: Science and Systems}, Daegu, Republic of
  Korea, July 2023.

\bibitem{shi2023waypoint}
L.~X. Shi, A.~Sharma, T.~Z. Zhao, and C.~Finn, ``Waypoint-based imitation
  learning for robotic manipulation,'' in \emph{Conference on Robot
  Learning}.\hskip 1em plus 0.5em minus 0.4em\relax PMLR, 2023, pp. 2195--2209.

\bibitem{grauman2022ego4d}
K.~Grauman, A.~Westbury, E.~Byrne, Z.~Chavis, A.~Furnari, R.~Girdhar,
  J.~Hamburger, H.~Jiang, M.~Liu, X.~Liu \emph{et~al.}, ``Ego4d: Around the
  world in 3,000 hours of egocentric video,'' in \emph{Proceedings of the
  IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 2022, pp.
  18\,995--19\,012.

\bibitem{resnet}
K.~He, X.~Zhang, S.~Ren, and J.~Sun, ``Deep residual learning for image
  recognition,'' in \emph{2016 IEEE Conference on Computer Vision and Pattern
  Recognition (CVPR)}, 2016, pp. 770--778.

\bibitem{perez2018film}
E.~Perez, F.~Strub, H.~De~Vries, V.~Dumoulin, and A.~Courville, ``Film: Visual
  reasoning with a general conditioning layer,'' in \emph{Proceedings of the
  AAAI conference on artificial intelligence}, vol.~32, 2018.

\bibitem{ross2010efficient_reductions}
S.~Ross and D.~Bagnell, ``Efficient reductions for imitation learning,'' in
  \emph{Proceedings of the thirteenth international conference on artificial
  intelligence and statistics}.\hskip 1em plus 0.5em minus 0.4em\relax JMLR
  Workshop and Conference Proceedings, 2010, pp. 661--668.

\bibitem{ross2011dagger}
S.~Ross, G.~Gordon, and D.~Bagnell, ``A reduction of imitation learning and
  structured prediction to no-regret online learning,'' in \emph{Proceedings of
  the fourteenth international conference on artificial intelligence and
  statistics}.\hskip 1em plus 0.5em minus 0.4em\relax JMLR Workshop and
  Conference Proceedings, 2011, pp. 627--635.

\bibitem{laskey2017comparing_hc_rc}
M.~Laskey, C.~Chuck, J.~Lee, J.~Mahler, S.~Krishnan, K.~Jamieson, A.~Dragan,
  and K.~Goldberg, ``Comparing human-centric and robot-centric sampling for
  robot deep learning from demonstrations,'' in \emph{2017 IEEE International
  Conference on Robotics and Automation (ICRA)}.\hskip 1em plus 0.5em minus
  0.4em\relax IEEE, 2017, pp. 358--365.

\bibitem{kelly2019hg_dagger}
M.~Kelly, C.~Sidrane, K.~Driggs-Campbell, and M.~J. Kochenderfer, ``Hg-dagger:
  Interactive imitation learning with human experts,'' in \emph{2019
  International Conference on Robotics and Automation (ICRA)}.\hskip 1em plus
  0.5em minus 0.4em\relax IEEE, 2019, pp. 8077--8083.

\bibitem{mandlekar2020human_in_the_loop}
A.~Mandlekar, D.~Xu, R.~Mart{\'\i}n-Mart{\'\i}n, Y.~Zhu, L.~Fei-Fei, and
  S.~Savarese, ``Human-in-the-loop imitation learning using remote
  teleoperation,'' \emph{arXiv preprint arXiv:2012.06733}, 2020.

\bibitem{chisari2022correct}
E.~Chisari, T.~Welschehold, J.~Boedecker, W.~Burgard, and A.~Valada, ``Correct
  me if i am wrong: Interactive learning for robotic manipulation,'' \emph{IEEE
  Robotics and Automation Letters}, vol.~7, no.~2, pp. 3695--3702, 2022.

\bibitem{kalashnikov2018scalable}
D.~Kalashnikov, A.~Irpan, P.~Pastor, J.~Ibarz, A.~Herzog, E.~Jang, D.~Quillen,
  E.~Holly, M.~Kalakrishnan, V.~Vanhoucke \emph{et~al.}, ``Scalable deep
  reinforcement learning for vision-based robotic manipulation,'' in
  \emph{Conference on robot learning}.\hskip 1em plus 0.5em minus 0.4em\relax
  PMLR, 2018, pp. 651--673.

\bibitem{abbeel2004apprenticeship}
P.~Abbeel and A.~Y. Ng, ``Apprenticeship learning via inverse reinforcement
  learning,'' in \emph{Proceedings of the twenty-first international conference
  on Machine learning}, 2004, p.~1.

\bibitem{ratliff2006maximum_margin}
N.~D. Ratliff, J.~A. Bagnell, and M.~A. Zinkevich, ``Maximum margin planning,''
  in \emph{Proceedings of the 23rd international conference on Machine
  learning}, 2006, pp. 729--736.

\bibitem{ratliff2009learning_to_search}
N.~D. Ratliff, D.~Silver, and J.~A. Bagnell, ``Learning to search: Functional
  gradient techniques for imitation learning,'' \emph{Autonomous Robots},
  vol.~27, no.~1, pp. 25--53, 2009.

\bibitem{ziebart2008maximum_entropy}
B.~D. Ziebart, A.~L. Maas, J.~A. Bagnell, A.~K. Dey \emph{et~al.}, ``Maximum
  entropy inverse reinforcement learning.'' in \emph{Aaai}, vol.~8.\hskip 1em
  plus 0.5em minus 0.4em\relax Chicago, IL, USA, 2008, pp. 1433--1438.

\bibitem{wulfmeier2015deep_inverse_rl}
M.~Wulfmeier, P.~Ondruska, and I.~Posner, ``Maximum entropy deep inverse
  reinforcement learning,'' \emph{arXiv preprint arXiv:1507.04888}, 2015.

\bibitem{finn2016guided_cost_learning}
C.~Finn, S.~Levine, and P.~Abbeel, ``Guided cost learning: Deep inverse optimal
  control via policy optimization,'' in \emph{International conference on
  machine learning}.\hskip 1em plus 0.5em minus 0.4em\relax PMLR, 2016, pp.
  49--58.

\bibitem{levine2014lqr_flm}
S.~Levine and P.~Abbeel, ``Learning neural network policies with guided policy
  search under unknown dynamics,'' \emph{Advances in neural information
  processing systems}, vol.~27, 2014.

\bibitem{das2021model_based_irl_from_vd}
N.~Das, S.~Bechtle, T.~Davchev, D.~Jayaraman, A.~Rai, and F.~Meier,
  ``Model-based inverse reinforcement learning from visual demonstrations,'' in
  \emph{Conference on Robot Learning}.\hskip 1em plus 0.5em minus 0.4em\relax
  PMLR, 2021, pp. 1930--1942.

\bibitem{ho2016gail}
J.~Ho and S.~Ermon, ``Generative adversarial imitation learning,''
  \emph{Advances in neural information processing systems}, vol.~29, 2016.

\bibitem{schulman2015trpo}
J.~Schulman, S.~Levine, P.~Abbeel, M.~Jordan, and P.~Moritz, ``Trust region
  policy optimization,'' in \emph{International conference on machine
  learning}.\hskip 1em plus 0.5em minus 0.4em\relax PMLR, 2015, pp. 1889--1897.

\bibitem{ho2016model}
J.~Ho, J.~Gupta, and S.~Ermon, ``Model-free imitation learning with policy
  optimization,'' in \emph{International conference on machine learning}.\hskip
  1em plus 0.5em minus 0.4em\relax PMLR, 2016, pp. 2760--2769.

\bibitem{brockman2016openai}
G.~Brockman, V.~Cheung, L.~Pettersson, J.~Schneider, J.~Schulman, J.~Tang, and
  W.~Zaremba, ``Openai gym,'' \emph{arXiv preprint arXiv:1606.01540}, 2016.

\bibitem{kostrikov2018discriminator}
I.~Kostrikov, K.~K. Agrawal, D.~Dwibedi, S.~Levine, and J.~Tompson,
  ``Discriminator-actor-critic: Addressing sample inefficiency and reward bias
  in adversarial imitation learning,'' in \emph{International Conference on
  Learning Representations}, 2018.

\bibitem{fu2018airl}
J.~Fu, K.~Luo, and S.~Levine, ``Learning robust rewards with adverserial
  inverse reinforcement learning,'' in \emph{International Conference on
  Learning Representations}, 2018.

\bibitem{ghasemipour2020divergence_minimization_perspective}
S.~K.~S. Ghasemipour, R.~Zemel, and S.~Gu, ``A divergence minimization
  perspective on imitation learning methods,'' in \emph{Conference on Robot
  Learning}.\hskip 1em plus 0.5em minus 0.4em\relax PMLR, 2020, pp. 1259--1277.

\bibitem{liu2018imitation_from_observation}
Y.~Liu, A.~Gupta, P.~Abbeel, and S.~Levine, ``Imitation from observation:
  Learning to imitate behaviors from raw video via context translation,'' in
  \emph{2018 IEEE International Conference on Robotics and Automation
  (ICRA)}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2018, pp. 1118--1125.

\bibitem{reddy2019sqil}
S.~Reddy, A.~D. Dragan, and S.~Levine, ``Sqil: Imitation learning via
  reinforcement learning with sparse rewards,'' in \emph{International
  Conference on Learning Representations}, 2019.

\bibitem{zolna2021task_relevant_ail}
K.~Zolna, S.~Reed, A.~Novikov, S.~G. Colmenarejo, D.~Budden, S.~Cabi, M.~Denil,
  N.~de~Freitas, and Z.~Wang, ``Task-relevant adversarial imitation learning,''
  in \emph{Conference on Robot Learning}.\hskip 1em plus 0.5em minus
  0.4em\relax PMLR, 2021, pp. 247--263.

\bibitem{rafailov2021visual_ail}
R.~Rafailov, T.~Yu, A.~Rajeswaran, and C.~Finn, ``Visual adversarial imitation
  learning using variational models,'' \emph{Advances in Neural Information
  Processing Systems}, vol.~34, pp. 3016--3028, 2021.

\bibitem{barth2018d4pg}
G.~Barth-Maron, M.~W. Hoffman, D.~Budden, W.~Dabney, D.~Horgan, D.~Tb,
  A.~Muldal, N.~Heess, and T.~Lillicrap, ``Distributed distributional
  deterministic policy gradients,'' \emph{arXiv preprint arXiv:1804.08617},
  2018.

\bibitem{li2021meta_watching_video_demonstration}
J.~Li, T.~Lu, X.~Cao, Y.~Cai, and S.~Wang, ``Meta-imitation learning by
  watching video demonstrations,'' in \emph{International Conference on
  Learning Representations}, 2021.

\bibitem{zhu2017cycle_gan}
J.-Y. Zhu, T.~Park, P.~Isola, and A.~A. Efros, ``Unpaired image-to-image
  translation using cycle-consistent adversarial networks,'' in
  \emph{Proceedings of the IEEE international conference on computer vision},
  2017, pp. 2223--2232.

\bibitem{sermanet2018time_contrastive}
P.~Sermanet, C.~Lynch, Y.~Chebotar, J.~Hsu, E.~Jang, S.~Schaal, S.~Levine, and
  G.~Brain, ``Time-contrastive networks: Self-supervised learning from video,''
  in \emph{2018 IEEE international conference on robotics and automation
  (ICRA)}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2018, pp. 1134--1141.

\bibitem{schroff2015triplet_loss}
F.~Schroff, D.~Kalenichenko, and J.~Philbin, ``Facenet: A unified embedding for
  face recognition and clustering,'' in \emph{Proceedings of the IEEE
  conference on computer vision and pattern recognition}, 2015, pp. 815--823.

\bibitem{zakka2022xirl}
K.~Zakka, A.~Zeng, P.~Florence, J.~Tompson, J.~Bohg, and D.~Dwibedi, ``Xirl:
  Cross-embodiment inverse reinforcement learning,'' in \emph{Conference on
  Robot Learning}.\hskip 1em plus 0.5em minus 0.4em\relax PMLR, 2022, pp.
  537--546.

\bibitem{merel2017learning}
J.~Merel, Y.~Tassa, D.~TB, S.~Srinivasan, J.~Lemmon, Z.~Wang, G.~Wayne, and
  N.~Heess, ``Learning human behaviors from motion capture by adversarial
  imitation,'' \emph{arXiv preprint arXiv:1707.02201}, 2017.

\bibitem{torabi2018gaifo}
F.~Torabi, G.~Warnell, and P.~Stone, ``Generative adversarial imitation from
  observation,'' \emph{arXiv preprint arXiv:1807.06158}, 2018.

\bibitem{torabi2018bco}
------, ``Behavioral cloning from observation,'' in \emph{Proceedings of the
  27th International Joint Conference on Artificial Intelligence}, 2018, pp.
  4950--4957.

\bibitem{torabi2021dealio}
------, ``Dealio: Data-efficient adversarial learning for imitation from
  observation,'' in \emph{2021 IEEE/RSJ International Conference on Intelligent
  Robots and Systems (IROS)}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE,
  2021, pp. 2391--2397.

\bibitem{chebotar2017pilqr}
Y.~Chebotar, K.~Hausman, M.~Zhang, G.~Sukhatme, S.~Schaal, and S.~Levine,
  ``Combining model-based and model-free updates for trajectory-centric
  reinforcement learning,'' in \emph{International conference on machine
  learning}.\hskip 1em plus 0.5em minus 0.4em\relax PMLR, 2017, pp. 703--711.

\bibitem{nair2017combining}
A.~Nair, D.~Chen, P.~Agrawal, P.~Isola, P.~Abbeel, J.~Malik, and S.~Levine,
  ``Combining self-supervised learning and imitation for vision-based rope
  manipulation,'' in \emph{2017 IEEE international conference on robotics and
  automation (ICRA)}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2017, pp.
  2146--2153.

\bibitem{guo2019hybrid_rl}
X.~Guo, S.~Chang, M.~Yu, G.~Tesauro, and M.~Campbell, ``Hybrid reinforcement
  learning with expert state sequences,'' in \emph{Proceedings of the AAAI
  Conference on Artificial Intelligence}, vol.~33, 2019, pp. 3739--3746.

\bibitem{radosavovic2021state_only_demo}
I.~Radosavovic, X.~Wang, L.~Pinto, and J.~Malik, ``State-only imitation
  learning for dexterous manipulation,'' in \emph{2021 IEEE/RSJ International
  Conference on Intelligent Robots and Systems (IROS)}.\hskip 1em plus 0.5em
  minus 0.4em\relax IEEE, 2021, pp. 7865--7871.

\bibitem{mnih2016a2c}
V.~Mnih, A.~P. Badia, M.~Mirza, A.~Graves, T.~Lillicrap, T.~Harley, D.~Silver,
  and K.~Kavukcuoglu, ``Asynchronous methods for deep reinforcement learning,''
  in \emph{International conference on machine learning}.\hskip 1em plus 0.5em
  minus 0.4em\relax PMLR, 2016, pp. 1928--1937.

\bibitem{Rajeswaran18_learning_complex_dexterous}
A.~Rajeswaran, V.~Kumar, A.~Gupta, G.~Vezzani, J.~Schulman, E.~Todorov, and
  S.~Levine, ``Learning complex dexterous manipulation with deep reinforcement
  learning and demonstrations,'' in \emph{Proceedings of Robotics: Science and
  Systems}, Pittsburgh, Pennsylvania, June 2018.

\bibitem{zhang2019solar}
M.~Zhang, S.~Vikram, L.~Smith, P.~Abbeel, M.~Johnson, and S.~Levine, ``Solar:
  Deep structured representations for model-based reinforcement learning,'' in
  \emph{International Conference on Machine Learning}.\hskip 1em plus 0.5em
  minus 0.4em\relax PMLR, 2019, pp. 7444--7453.

\bibitem{Kingma2014_vae}
D.~P. Kingma and M.~Welling, ``{Auto-Encoding Variational Bayes},'' in
  \emph{2nd International Conference on Learning Representations, {ICLR} 2014,
  Banff, AB, Canada, April 14-16, 2014, Conference Track Proceedings}, 2014.

\bibitem{devin2018deep}
C.~Devin, P.~Abbeel, T.~Darrell, and S.~Levine, ``Deep object-centric
  representations for generalizable robot learning,'' in \emph{2018 IEEE
  International Conference on Robotics and Automation (ICRA)}.\hskip 1em plus
  0.5em minus 0.4em\relax IEEE, 2018, pp. 7111--7118.

\bibitem{park2021object}
J.~Park, Y.~Seo, C.~Liu, L.~Zhao, T.~Qin, J.~Shin, and T.-Y. Liu,
  ``Object-aware regularization for addressing causal confusion in imitation
  learning,'' \emph{Advances in Neural Information Processing Systems},
  vol.~34, pp. 3029--3042, 2021.

\bibitem{belkhale2023plato}
S.~Belkhale and D.~Sadigh, ``Plato: Predicting latent affordances through
  object-centric play,'' in \emph{Conference on Robot Learning}.\hskip 1em plus
  0.5em minus 0.4em\relax PMLR, 2023, pp. 1424--1434.

\bibitem{zhu2023viola}
Y.~Zhu, A.~Joshi, P.~Stone, and Y.~Zhu, ``Viola: Imitation learning for
  vision-based manipulation with object proposal priors,'' in \emph{Conference
  on Robot Learning}.\hskip 1em plus 0.5em minus 0.4em\relax PMLR, 2023, pp.
  1199--1210.

\bibitem{zhu2023learning}
Y.~Zhu, Z.~Jiang, P.~Stone, and Y.~Zhu, ``Learning generalizable manipulation
  policies with object-centric 3d representations,'' in \emph{Conference on
  Robot Learning}.\hskip 1em plus 0.5em minus 0.4em\relax PMLR, 2023, pp.
  3418--3433.

\bibitem{jiang2023vima}
Y.~Jiang, A.~Gupta, Z.~Zhang, G.~Wang, Y.~Dou, Y.~Chen, L.~Fei-Fei,
  A.~Anandkumar, Y.~Zhu, and L.~Fan, ``Vima: General robot manipulation with
  multimodal prompts,'' in \emph{Fortieth International Conference on Machine
  Learning}, 2023.

\bibitem{fastrcnn}
R.~Girshick, ``Fast r-cnn,'' in \emph{2015 IEEE International Conference on
  Computer Vision (ICCV)}, 2015, pp. 1440--1448.

\bibitem{lin2014microsoft}
T.-Y. Lin, M.~Maire, S.~Belongie, J.~Hays, P.~Perona, D.~Ramanan,
  P.~Doll{\'a}r, and C.~L. Zitnick, ``Microsoft coco: Common objects in
  context,'' in \emph{Computer Vision--ECCV 2014: 13th European Conference,
  Zurich, Switzerland, September 6-12, 2014, Proceedings, Part V 13}.\hskip 1em
  plus 0.5em minus 0.4em\relax Springer, 2014, pp. 740--755.

\bibitem{vaswani2017attention}
A.~Vaswani, N.~Shazeer, N.~Parmar, J.~Uszkoreit, L.~Jones, A.~N. Gomez, L.~u.
  Kaiser, and I.~Polosukhin, ``Attention is all you need,'' in \emph{Advances
  in Neural Information Processing Systems}, I.~Guyon, U.~V. Luxburg,
  S.~Bengio, H.~Wallach, R.~Fergus, S.~Vishwanathan, and R.~Garnett, Eds.,
  vol.~30.\hskip 1em plus 0.5em minus 0.4em\relax Curran Associates, Inc.,
  2017.

\bibitem{johnson2017clevr}
J.~Johnson, B.~Hariharan, L.~Van Der~Maaten, L.~Fei-Fei, C.~Lawrence~Zitnick,
  and R.~Girshick, ``Clevr: A diagnostic dataset for compositional language and
  elementary visual reasoning,'' in \emph{Proceedings of the IEEE conference on
  computer vision and pattern recognition}, 2017, pp. 2901--2910.

\bibitem{chen2022caan}
C.~Chen, D.~Han, and C.-C. Chang, ``Caan: Context-aware attention network for
  visual question answering,'' \emph{Pattern Recognition}, vol. 132, p. 108980,
  2022.

\bibitem{chen2024mpcct}
------, ``Mpcct: Multimodal vision-language learning paradigm with
  context-based compact transformer,'' \emph{Pattern Recognition}, vol. 147, p.
  110084, 2024.

\bibitem{liu2024visual}
H.~Liu, C.~Li, Q.~Wu, and Y.~J. Lee, ``Visual instruction tuning,''
  \emph{Advances in neural information processing systems}, vol.~36, 2024.

\bibitem{resnet21}
D.~Tran, H.~Wang, L.~Torresani, J.~Ray, Y.~LeCun, and M.~Paluri, ``A closer
  look at spatiotemporal convolutions for action recognition,'' in
  \emph{Proceedings of the IEEE conference on Computer Vision and Pattern
  Recognition}, 2018, pp. 6450--6459.

\bibitem{bhutani2022attentive_one_shot}
V.~Bhutani, A.~Majumder, M.~Vankadari, S.~Dutta, A.~Asati, and S.~Kumar,
  ``Attentive one-shot meta-imitation learning from visual demonstration,'' in
  \emph{2022 International Conference on Robotics and Automation (ICRA)}, 2022,
  pp. 8584--8590.

\bibitem{doasIcan2022}
\BIBentryALTinterwordspacing
B.~Ichter, A.~Brohan, Y.~Chebotar, C.~Finn, K.~Hausman, A.~Herzog, D.~Ho,
  J.~Ibarz, A.~Irpan, E.~Jang, R.~Julian, D.~Kalashnikov, S.~Levine, Y.~Lu,
  C.~Parada, K.~Rao, P.~Sermanet, A.~Toshev, V.~Vanhoucke, F.~Xia, T.~Xiao,
  P.~Xu, M.~Yan, N.~Brown, M.~Ahn, O.~Cortes, N.~Sievers, C.~Tan, S.~Xu,
  D.~Reyes, J.~Rettinghouse, J.~Quiambao, P.~Pastor, L.~Luu, K.~Lee, Y.~Kuang,
  S.~Jesmonth, N.~J. Joshi, K.~Jeffrey, R.~J. Ruano, J.~Hsu, K.~Gopalakrishnan,
  B.~David, A.~Zeng, and C.~K. Fu, ``Do as {I} can, not as {I} say: Grounding
  language in robotic affordances,'' in \emph{Conference on Robot Learning,
  CoRL 2022, 14-18 December 2022, Auckland, New Zealand}, ser. Proceedings of
  Machine Learning Research, K.~Liu, D.~Kulic, and J.~Ichnowski, Eds., vol.
  205.\hskip 1em plus 0.5em minus 0.4em\relax {PMLR}, 2022, pp. 287--318.
  [Online]. Available: \url{https://proceedings.mlr.press/v205/ichter23a.html}
\BIBentrySTDinterwordspacing

\bibitem{mees2022hulc}
O.~Mees, L.~Hermann, and W.~Burgard, ``What matters in language conditioned
  robotic imitation learning over unstructured data,'' \emph{IEEE Robotics and
  Automation Letters (RA-L)}, vol.~7, no.~4, pp. 11\,205--11\,212, 2022.

\bibitem{finn2017maml}
C.~Finn, P.~Abbeel, and S.~Levine, ``Model-agnostic meta-learning for fast
  adaptation of deep networks,'' in \emph{International conference on machine
  learning}.\hskip 1em plus 0.5em minus 0.4em\relax PMLR, 2017, pp. 1126--1135.

\bibitem{finn2017one_shot_visual_il}
C.~Finn, T.~Yu, T.~Zhang, P.~Abbeel, and S.~Levine, ``One-shot visual imitation
  learning via meta-learning,'' in \emph{Conference on robot learning}.\hskip
  1em plus 0.5em minus 0.4em\relax PMLR, 2017, pp. 357--368.

\bibitem{yu2018one_shot_hil}
T.~Yu, P.~Abbeel, S.~Levine, and C.~Finn, ``One-shot hierarchical imitation
  learning of compound visuomotor tasks,'' \emph{arXiv preprint
  arXiv:1810.11043}, 2018.

\bibitem{duan2017one_shot_il}
Y.~Duan, M.~Andrychowicz, B.~Stadie, O.~Jonathan~Ho, J.~Schneider,
  I.~Sutskever, P.~Abbeel, and W.~Zaremba, ``One-shot imitation learning,''
  \emph{Advances in neural information processing systems}, vol.~30, 2017.

\bibitem{pennington2014glove}
J.~Pennington, R.~Socher, and C.~D. Manning, ``Glove: Global vectors for word
  representation,'' in \emph{Proceedings of the 2014 conference on empirical
  methods in natural language processing (EMNLP)}, 2014, pp. 1532--1543.

\bibitem{tan2019efficientnet}
M.~Tan and Q.~Le, ``Efficientnet: Rethinking model scaling for convolutional
  neural networks,'' in \emph{International conference on machine
  learning}.\hskip 1em plus 0.5em minus 0.4em\relax PMLR, 2019, pp. 6105--6114.

\bibitem{cer2018universal}
D.~Cer, Y.~Yang, S.-y. Kong, N.~Hua, N.~Limtiaco, R.~S. John, N.~Constant,
  M.~Guajardo-Cespedes, S.~Yuan, C.~Tar \emph{et~al.}, ``Universal sentence
  encoder,'' \emph{arXiv preprint arXiv:1803.11175}, 2018.

\bibitem{ryoo2021tokenlearner}
M.~Ryoo, A.~Piergiovanni, A.~Arnab, M.~Dehghani, and A.~Angelova,
  ``Tokenlearner: Adaptive space-time tokenization for videos,'' \emph{Advances
  in neural information processing systems}, vol.~34, pp. 12\,786--12\,797,
  2021.

\bibitem{grill2003neural}
K.~Grill-Spector, ``The neural basis of object perception,'' \emph{Current
  opinion in neurobiology}, vol.~13, no.~2, pp. 159--166, 2003.

\bibitem{mees2023hulc++}
O.~Mees, J.~Borja-Diaz, and W.~Burgard, ``Grounding language with visual
  affordances over unstructured data,'' in \emph{2023 IEEE International
  Conference on Robotics and Automation (ICRA)}.\hskip 1em plus 0.5em minus
  0.4em\relax IEEE, 2023, pp. 11\,576--11\,582.

\bibitem{reuss2024multimodal}
M.~Reuss, {\"O}.~E. Ya{\u{g}}murlu, F.~Wenzel, and R.~Lioutikov, ``Multimodal
  diffusion transformer: Learning versatile behavior from multimodal goals,''
  in \emph{First Workshop on Vision-Language Models for Navigation and
  Manipulation at ICRA 2024}, 2024.

\bibitem{shridhar2022cliport}
M.~Shridhar, L.~Manuelli, and D.~Fox, ``Cliport: What and where pathways for
  robotic manipulation,'' in \emph{Conference on robot learning}.\hskip 1em
  plus 0.5em minus 0.4em\relax PMLR, 2022, pp. 894--906.

\bibitem{radford2021learning}
A.~Radford, J.~W. Kim, C.~Hallacy, A.~Ramesh, G.~Goh, S.~Agarwal, G.~Sastry,
  A.~Askell, P.~Mishkin, J.~Clark \emph{et~al.}, ``Learning transferable visual
  models from natural language supervision,'' in \emph{International conference
  on machine learning}.\hskip 1em plus 0.5em minus 0.4em\relax PMLR, 2021, pp.
  8748--8763.

\bibitem{zeng2021transporter}
A.~Zeng, P.~Florence, J.~Tompson, S.~Welker, J.~Chien, M.~Attarian,
  T.~Armstrong, I.~Krasin, D.~Duong, V.~Sindhwani \emph{et~al.}, ``Transporter
  networks: Rearranging the visual world for robotic manipulation,'' in
  \emph{Conference on Robot Learning}.\hskip 1em plus 0.5em minus 0.4em\relax
  PMLR, 2021, pp. 726--747.

\bibitem{cui2023from}
Z.~J. Cui, Y.~Wang, N.~M.~M. Shafiullah, and L.~Pinto, ``From play to policy:
  Conditional behavior generation from uncurated robot data,'' in \emph{The
  Eleventh International Conference on Learning Representations}, 2023.

\bibitem{ur5e}
\BIBentryALTinterwordspacing
U.~Robots, ``Ur5e cobot per automazione industriale.'' [Online]. Available:
  \url{https://www.universal-robots.com/it/prodotti/robot-ur5/}
\BIBentrySTDinterwordspacing

\bibitem{robotiq}
\BIBentryALTinterwordspacing
Robotiq, ``Pinze modello 2f-85.'' [Online]. Available:
  \url{https://robotiq.com/it/prodotti/pinze-modello-2f-85-e-2f-140}
\BIBentrySTDinterwordspacing

\bibitem{zed}
\BIBentryALTinterwordspacing
------, ``Zed mini - mixed reality.'' [Online]. Available:
  \url{https://www.stereolabs.com/zed-mini/}
\BIBentrySTDinterwordspacing

\end{thebibliography}
