\chapter*{Abstract}
% 5 PAGINE E UN PO
\label{ch:abstract}
La robotica è una delle tecnologie più importanti della società moderna. I progressi nei campi dell'informazione, dell'elettronica e della meccanica ci permettono di costruire e programmare macchine per svolgere compiti nei contesti più disparati, come l'industria, la chirurgia e il settore aerospaziale.
\newline In particolare, nella produzione manifatturiera, i robot vengono utilizzati principalmente per eseguire lavori ripetitivi e potenzialmente dannosi per l'uomo.
% come l'assemblaggio, la saldatura e la movimentazione di materiali pesanti o pericoli. Questo è possibile grazie alla ben nota robustezza meccanica e alla capacità di ripetere gli stessi movimenti con alta precisione e accuratezza.

In passato, i sistemi robotici venivano utilizzati in contesti con forti limitazioni date dal fatto che l'ambiente era chiuso e noto a priori. Negli ultimi decenni, grazie anche allo sviluppo del paradigma dell'Industria 4.0, i robot sono immersi in contesti più flessibili, rappresentati da ambienti non noti o parzialmente noti a priori, dove devono \textbf{coesistere} e \textbf{cooperare} con gli esseri umani, risolvendo diversi compiti \textbf{dinamici} \cite{bini2023multi} (ad esempio, prelevare un oggetto richiesto la cui posizione non è nota a priori).

In questo scenario, le caratteristiche desiderate di tali sistemi robotici sono:
\begin{enumerate*}[label=\textbf{(\alph*)}]
\item \textbf{Adattabilità a nuove condizioni}, ossia il sistema deve essere in grado di adattarsi facilmente ai cambiamenti delle condizioni di contesto, mostrando comportamenti \textit{``intelligenti"} per affrontare questi nuovi scenari andando a risolvere il problema di interesse;
\item \textbf{Adattabilità a nuovi compiti}, ossia il sistema deve essere in grado di adattarsi facilmente sia a nuove varianti di un compito conosciuto che a compiti completamente nuovi, sfruttando l'esperienza per inferire le azioni necessarie a risolverli.
\end{enumerate*}

% Questi requisiti possono risultare difficili da raggiungere con le tecniche tradizionali di programmazione robotica basate su politiche di controllo definite manualmente. Queste tecniche convenzionali richiedono spesso un'analisi meticolosa delle dinamiche del processo, la costruzione di un modello analitico e la derivazione di una legge di controllo che soddisfi criteri di progettazione specifici. Questo processo di progettazione può risultare tedioso richiedendo tempo e soprattutto particolarmente costoso, soprattutto quando vengono utilizzati sistemi di percezione avanzati (telecamere, microfoni, sensori di movimento) per dedurre lo stato dell'ambiente (come la posizione di un oggetto desiderato) e le intenzioni dell'operatore umano.

Per raggiungere questi requisiti sono state ampiamente utilizzate \textit{tecniche di apprendimento}, in cui la politica di controllo viene dedotta dai dati. Questi dati possono essere generati sia tramite \textbf{l'esperienza dell'agente} \cite{sutton2018reinforcement} che tramite \textbf{dimostrazioni di esperti} \cite{osa2018algorithmic}.
% \newline Nel caso dell'esperienza dell'agente, c'è una procedura \textit{trianl-and-error} in cui la politica di controllo genera azioni eseguite da un agente, che interagisce con l'ambiente. I parametri vengono poi adattati in base all'efficacia delle azioni, tenendo conto del loro impatto sull'ambiente rispetto al compito da risolvere.
Nel caso delle dimostrazioni di esperti, i parametri della politica di controllo vengono direttamente adattati utilizzando un dataset contenente esempi dell'esecuzione del compito. L'obiettivo qui è replicare i compiti osservati nel dataset.

La presente tesi si contestualizza nel \textit{Learning from Demonstration} (LfD), un approccio di apprendimento basato su dimostrazioni di esperti. Rispetto i requisiti di adattabilità, la tesi si concentra su un aspetto specifico dell'LfD, denominato \textit{Multi-Task LfD}. In questo caso, la politica di controllo viene addestrata per gestire varie varianti di uno specifico compito (ad esempio, prendere un oggetto da diverse posizioni possibili) \cite{dasari2021transformers_one_shot} o persino compiti completamente diversi (ad esempio, una singola politica di controllo che risolve sia compiti di pick-and-place sia compiti di assemblaggio) \cite{brohan2022rt,mandi2022towards_more_generalizable_one_shot}, con l'obiettivo di generalizzare non solo rispetto agli oggetti manipolati e alle condizioni iniziali, ma anche rispetto ai compiti stessi. Questo significa che, sfruttando l'ipotesi del \textit{knowledge-sharing}, possiamo ottenere un sistema in grado di risolvere nuove variazioni.

% non viene addestrata per eseguire un singolo compito (ad esempio, prendere un oggetto) con l'obiettivo di generalizzare rispetto a diversi oggetti e condizioni iniziali \cite{zhang2018deep_vr_teleoperation,mandlekar2022matters}. Piuttosto, 

In questo scenario, bisogna definire un \textbf{segnale di condizionamento} (ossia, il segnale che informa la politica sul compito da eseguire, l'oggetto da manipolare e la posizione di destinazione). Inoltre, l'ambiente può contenere diversi \textbf{oggetti distrattori} (ad esempio, oggetti che potrebbero essere manipolati ma che non sono di interesse per una determinata variazione del compito).

Per quanto riguarda il segnale di condizionamento, si possono definire almeno due approcci. Il primo rappresentato da una descrizione in linguaggio naturale del compito da eseguire \cite{stepputtis2020language,mees2022calvin,brohan2022rt}, il secondo è rappresentato da una dimostrazione video \cite{dasari2021transformers_one_shot,mandi2022towards_more_generalizable_one_shot}.
% \newline Nel primo caso, il compito è descritto utilizzando frasi che specificano i dettagli del compito, come ``Take the red bot and place into the first bin". Fornita la frase in ingresso, il sistema deve essere in grado di dedurre l'intento del compito (ossia, l'operazione di presa e posizionamento) e l'oggetto di interesse (ad esempio, la scatola rossa da prendere e il primo contenitore per il posizionamento) e correlare queste informazioni con l'ambiente e lo stato del robot per controllarlo in modo efficace.
\newline Il caso di interesse per la tesi è il secondo, dove un altro agente (sia esso un robot o un operatore umano) esegue il compito in una diversa configurazione ambientale, registra questa esecuzione e fornisce il video come input alla politica di controllo. La politica di controllo deve quindi dedurre l'intento dal video (ossia, il compito da eseguire, l'oggetto da manipolare e lo stato finale) e controllare il robot per completare il compito in base allo stato dell'agente, allo stato dell'ambiente e al compito comandato.

% Prendendo inspirazione  da come gli esseri umani possono imparare a replicare compiti semplicemente osservandone l'esecuzione di questi ultimi, l'obiettivo principale di questa tesi è sviluppare un sistema in grado di replicare i compiti mostrati in una dimostrazione video. Questo comporta affrontare sfide legate all'estrazione di informazioni rilevanti per il compito dal video, come l'identificazione dell'oggetto manipolato e la sua posizione finale.

Per quanto riguarda il problema legato alla presenza di oggetti distrattori, in generale questi sono oggetti che non vengono mai considerati in operazioni di manipolazione, semplificando di molto il problema. Tuttavia, nel contesto proposto in questa tesi, il problema è ulteriormente enfatizzato dal fatto che il significato semantico di oggetto di interesse o distrattore  è definito a run-time dal comando stesso. Questo significa che se la configurazione iniziale è composta da quattro oggetti (ad esempio, quattro box di colore diverso), sulla base del comando dato al robot un determinato oggetto può diventare o meno di interesse.

Il principale contributo di questa tesi è quello di svillupare un sistema che sia robusto alla presenza di distrattori all'interno della scena. Nello specifico, un problema chiave identificato in letteratura è la \textbf{target missidentification}, questo significa che la politica di controllo appresa genera traiettorie valide, permettendo al robot di raggiungere, prendere e posizionare oggetti, ma manipolando l'oggetto sbagliato.

Per risolvere questo problema, sono state fatte due considerazioni principali:
\begin{enumerate*}[label=\textbf{(\arabic*)}] 
    \item Le architetture proposte in letteratura sono prevalentemente \textbf{end-to-end}, questo significa che traducono input ad alta dimensionalità (immagini) nelle corrispondenti azioni (posa del gripper rispetto ad un frame di riferimento). Con questo approccio, il modello deve imparare una rappresentazione implicita che codifica sia l'obiettivo del compito che lo stato corrente dell'ambiente, compresa la posizione dell'oggetto target;
    \item La procedura di apprendimento ottimizza una funzione di errore che si focalizza esclusivamente sull'azione, questo significa che il sistema durante l'addestramento ha come obiettivo quello di generare in media le stesse azioni presenti nel dataset. Questa procedura può portare il sistema al non focalizzarsi sulla codifica di informazioni di interesse come la posizione degli oggetti. 
\end{enumerate*}

Questi due fattori possono portare a una politica di controllo che non riesce a guidare efficacemente il robot verso l'oggetto target. In particolare, è stato osservato che le fasi iniziali dell'esecuzione della traiettoria sono cruciali. Infatti, anche piccoli errori durante questi primi passi possono portare il robot al raggiungimento e la presa dell'oggetto sbagliato.

Basandosi su queste considerazioni, questa tesi esplora lo sviluppo di un'architettura \textbf{modulare}, in contrapposizione agli approcci end-to-end proposti in letteratura. Questa architettura prevede moduli specificamente progettati per ragionare sulle zone di interesse (ad esempio, la posizione dell'oggetto target e la posizione finale di posizionamento). Quindi, una volta individuate queste zone di interesse, attraverso la generazione di bounding-box, questi possono essere integrati nell'input del modulo di controllo, che ora riceve anche informazioni a bassa dimensionalità, come la posizione dell'oggetto target, che possono essere più facilmente utilizzate durante il processo di apprendimento, soprattutto alla luce della perdita centrata sull'imitazione dell'azione.
% Gli output di questi moduli di ragionamento vengono poi integrati per semplificare il problema di apprendimento per il Modulo di Controllo. Questo modulo ora riceve informazioni a bassa dimensionalità, come la posizione dell'oggetto target, che possono essere più facilmente utilizzate durante il processo di apprendimento, soprattutto alla luce della perdita centrata sull'imitazione dell'azione.

Per eseguire questo ragionamento esplicito, è stato sviluppato un \textit{Conditioned Object Detector} (COD). Questo modulo, dato in input il video della dimostrazione e l'osservazione corrente dell'agente, predice il bounding-box relativo all'oggetto target e alla posizione finale.

La procedura di apprendimento viene quindi suddivisa in due fasi. La prima fase prevede l'addestramento del modulo COD, focalizzandosi sulla risoluzione dei problemi cognitivi di detection. La seconda fase prevede l'addestramento della \textit{Object-Conditioned Control Policy} (OCCP), che si concentra sulla risoluzione del problema di controllo sfruttando le informazioni posizionali generati dal COD.

Il sistema finale è stato ampiamente testato in simulato, dove è possibile generare scenari e collezionare traiettorie per il dataset. La validazione del sistema si è conclusa attraverso il testing dei metodi proposti su una piattaforma robotica reale. 

Per quanto riguarda l'ambiente simulato, il sistema è stato valutato sia in scenari definiti \textbf{multi-variation single-task} che in scenari definiti \textbf{multi-variation multi-task}, considerando quattro compiti: Pick-Place, Nut-Assembly, Stack-Block e Press-Button. Ogni task è caratterizzato dalla presenza di diverse varianti definite sulla base dell'oggetto manipolato e del suo stato finale. Per esempio, nel task di Pick-Place sono presenti 4 box e 4 bin, le variazioni sono rappresentate dalle possibili combinazioni di box da prelevare e bin dove eseguire il placing. 

I task selezionati sono caratterizzate dalla presenza sia di caratteristiche comuni, ma anche di caratteristiche specifiche. Ad esempio, il compito di Nut-Assembly comporta una manipolazione precisa, mentre il Pick-Place può essere risolto in modo molto più approssimativo.

Nel complesso, i metodi proposti hanno dimostrato comportamenti molto promettenti e un miglioramento generale rispetto ai metodi di base che non includono il ragionamento sugli oggetti. Nello specifico, nello scenario multi-variation single-task, il miglior metodo proposto ha raggiunto un tasso di successo medio del \textbf{90.13\%} che rappresenta un miglioramento del \textbf{+28.78\%} rispetto alla baseline utilzzata. Invece, nello scenario multi-variation multi-task, il miglio metodo proposto ha raggiunto un tasso di successo medio del \textbf{79.24\%} che rappresenta un miglioramento del \textbf{+33.23\%} rispetto alla baseline utilizzata. 

Ciò dimostra che risolvere compiti di manipolazione con un approccio orientato agli oggetti può essere un paradigma efficace per i problemi di LfD. Inoltre, questo approccio fornisce informazioni interpretabili all'utente finale, poiché i bounding-box predetti possono essere interpretati come le posizioni verso cui si muoverà il robot.

In conclusione, il metodo proposto è stato testato anche in un ambiente reale, dove la complessità del problema è aumentata dalla presenza di meno dati e rumorosi raccolti tramite teleoperazione. Anche in queste condizioni, il metodo proposto ha dimostrato la sua efficacia nell'affrontare sia i problemi cognitivi che quelli di controllo, raggiungento un tasso di successo del \textbf{55.00\%}, che risulta un netto miglioramento rispetto allo \textbf{0.00\%} della baseline a parità di condizioni di addestramento. Ciò conferma che l'informazione legata all'oggetto di interesse può essere applicata con successo in scenari reali, consentendo lo sviluppo di un sistema affidabile nonostante dati limitati e rumorosi.